%DO NOT MESS AROUND WITH THE CODE ON THIS PAGE UNLESS YOU %REALLY KNOW WHAT YOU ARE DOIN

\chapter{Implementation and Methodology} \label{Implementation and Methodology}

\section{Tools Used } \label{Tools Used }
\subsection{Microsoft Kinect v2 sensor} \label{Microsoft Kinect v2 sensor} 
\noindent Specification of the Kinect are discussed in chapted 3.
\subsection{Visual Studio 2015 Community Edition }\label{Visual Studio 2015 Community Edition }  
\noindent Microsoft Visual Studio is an integrated development environment (IDE) from Microsoft. It is used to develop computer programs for Microsoft Windows, as well as web sites, web apps, web services and mobile apps. Visual Studio uses Microsoft software development platforms such as Windows API, Windows Forms, Windows Presentation Foundation, Windows Store and Microsoft Silverlight. It can produce both native code and managed code. Visual Studio supports different programming languages and allows the code editor and debugger to support (to varying degrees) nearly any programming language, provided a language-specific service exists. Built-in languages include C, C++and C++/CLI (via VisualC++), VB.NET (via VisualBasic.NET), C\# (via Visual C\#), and F\# (as of Visual Studio 2010). Support for other languages such as Python, Ruby, Node.js, and M among others is available via language services installed separately.

\noindent Microsoft provides the Kinect SDK and Kinect specific libraries to be used on Visual Studio. This is the reason we have chosen Visual Studio as our development platform as it makes interfacing the Kinect easy. 

\subsection{Vitruvius }\label{Vitruvius}
\noindent Vitruvius is an advanced kinect framework which provides a set of easy to use kinect utilities on Visual Studio and unity that simplify and speed up many aspects of Kinect for Windows App development.The product also alleviates alot of the heavy math associated with implementing motion tracking in advanced kinect apps.

\noindent Vitruvius lets you easily calculate joint angles and find the length of specified segments in 3D space, and the rotation of the body in the X, Y, Z axis.
Vitruvius also provides simplified bitmap manipulation and lets you take full advantage of the latest Kinect for Windows facial tracking and gesture detection for Windows human-computing interactions.
 
\noindent We used the Vitruvius Library on top of the SDK to simplify the maesuremnt of length and angles.

\subsection{Notepad++ }\label{Notepad++ } 
\noindent Notepad++ is a text editor and source code editor for use with Microsoft Windows. It supports tabbed editing, which allows working with multiple open files in a single window. Notepad++ is distributed as free software. It supports syntax highlighting and code folding for over 50 programming, scripting, and markup languages.

\noindent The skeletal data obtained from the SDK is stored in CSV format in a Notepad++.

\subsection{MATLAB R2015a }\label{MATLAB R2015a }
\noindent MATLAB is a multi-paradigm numerical computing environment and fourth-generation programming language. A proprietary programming language developed by MathWorks, MATLAB allows matrix manipulations, plotting of functions and data, implementation of algorithms, creation of user interfaces, and interfacing with programs written in other languages, including C, C++, C\#, Java, Fortran and Python.

\noindent MATLAB provides special toolboxes for applications such as Signal Processing and Communications, Control System Design and Analysis, Pattern Recognition, Classification Learner and other statistical modelling. The CSV format file is processed in MATLAB for gait feature extraction and classification. 

\newpage
\section{Gait Features} \label{Gait Features } 
\noindent The Kinect SDK offers the detection and tracking of 25 different skeletal joints. The features that can be generated from these joints can broadly be classified as static and kinematic features.
The static features are the ones which do not change in time as a person is walking, for e.g. height. We define a set of 7 static features used in our study.
\def\arraystretch{1.3}
\begin{table}[h]
\centering
\begin{tabular}{| p{2cm} | |p{5cm}|}
 \hline
\cellcolor{pink} SR No. & \cellcolor{pink} Static Features  \\ \hline
1 & Height \\ \hline
2 & Length of Full Arms \\ \hline
3 & Length of Fore Arms \\\hline
4 & Length of Upper Arms \\ \hline
5 & Length of Full Legs \\ \hline
6 & Length of Thighs \\\hline
7 & Length of Lower Legs \\ \hline
\end{tabular}
\caption{The set of static features}
\end{table}

\noindent Kinematic features basically involve distance and angle between joints while a person is walking. The value of these features constantly change during the walk and are shown to be periodic in nature. We define a set of 8 kinematic features involving distance between joints.
\def\arraystretch{1.3}
\begin{table}[h]
\centering
\begin{tabular}{| p{2cm} | |p{6cm}|}
 \hline
\cellcolor{pink} SR No. & \cellcolor{pink} Features  \\ \hline
1 & Distance between ankles \\ \hline
2 & Distance between knees \\ \hline
3 & Distance between elbows \\\hline
4 & Distance between hands \\ \hline
5 & variance of head (along x) \\ \hline
6 & variance of head (along y) \\\hline
7 & variance of left knee (along y) \\ \hline
8 & variance of right knee (along y) \\ \hline
\end{tabular}
\caption{ Kinematic features involving distance between joints}
\end{table}

\newpage
\noindent When we talk about the features such as variance of head and knees along X and Y. We are trying to map the vertical and lateral oscillations of these skeleton joints. Features involving angles are extracted during the walk but are not used in this study and will be discussed later.

\newpage
\section{Experimental Set up } \label{Experimental Set up }

\noindent The Kinect was placed at height of 1.5m and the person was made to walk in front of the Kinect. The figure\ref{fig:exp.png} gives us a nice visual  representation of the setup.\\
\begin{figure}[h]
\centering
\includegraphics[scale=0.55]{exp.png}
\caption{Experimental Setup}
\label{fig:exp.png}
\end{figure}

\noindent Initially, the person is made to stand in a straight posture at the maximum range of Kinect (close to 4.5m). Here the static feature readings are taken for a period of about 3 seconds.

\noindent Then the person is asked to walk straight towards the Kinect. We are interested in the kinematic features of the walk upto a distance of 1.5m from the Kinect, because within this range we are able to capture the motion of the entire body. Beyond this,some part of the joints always goes out of the frame.

\noindent Although the range of 3m (4.5-1.5 m) appears small. It is more than adequate to extract one complete gait cycle. The representation of this gait cycle is shown in Figure \ref{fig:exp.png}.

\newpage

\section{Logic behind the computation of static and kinematic features}\label{Logic behind the computation of static and kinematic features} 

\subsection{Computation of length between joints}\label{Computation of length between joints} 

\noindent We refer back to the figure depicting all the body joints represented by the Kinect.\\
\begin{figure}[h]
\centering
\includegraphics[scale=0.85]{Figbodjoints.png}
\caption{25 joints offered by Kinect}
\label{fig:Figbodjoints.png}
\end{figure}
\noindent For explanatory purposes we will show how height is measured. In principle same logic is applied to get other measurements and distances.
Kinect provides you with the coordinates (X, Y and Z) of 25 skeleton joints. We might think that a person's height is the distance from the head joint to a foot joint, right? This is fundamentally incorrect because users might stand with a bended knee, they might lean a bit to the left or to the right. If you try to calculate the distance defined from the head joint to one of the foot joints, you'll get a far from accurate result.\\

\noindent If we examine the skeleton joints as seen in figure \ref{fig:Figbodjoints.png} we'll notice that the height is the sum of the lengths of the following line segments:\\
\noindent$\bullet$   Head – Neck\\
$\bullet$	Neck – Spine Shoulder\\
$\bullet$	Spine Shoulder – Spine Mid\\
$\bullet$	Spine Mid – Spine Base\\
$\bullet$	Hip Left/Hip Right – Knee Left / Knee Right\\
$\bullet$	Knee Left / Knee Right – Ankle Left / Ankle Right\\
$\bullet$	Ankle Left / Ankle Right – Foot Left / Foot Right\\

\noindent Using (X,Y,Z) coordinates of each joint we can calculate the length of the line defined by two joints in the 3D space, simply by using the distance formula:

 D = $\sqrt{(x_{1}-x_{2})^2+ (y_{1}-y_{2})^2+(z_{1}-z_{2})^2}$

\noindent Pretty straightforward till here. But, how will we determine which leg corresponds to the most accurate user height? Hence we take the average of both the legs and then add this to the sum of the rest of the joints.
It should be noted that the height calculated in this case does not represent the true height because Kinect only gives you the centre of the head joint. It does not detect the end of the head for accurate measurements. Also height measured in this study excluded the foot left and right joints, as they being close to the floor gave readings prone to error.

\noindent Hence for all intent and purposes, whenever we talk about height in this study it will be the sum of the lengths of the line segments:

\noindent Head -$>$ Neck -$>$ Spine Shoulder -$>$ Spine Mid -$>$ Spine Base -$>$ HipLeft/HipRight -$>$ KneeLeft/KneeRight -$>$ AnkleLeft/AnkleRight\\ 
Where distances from the hip joint to the ankle joint gets averaged for the two legs.
\newpage

\subsection{ Evaluation of angles between joints} \label{ Evaluation of angles between joints}
We present a new gait feature that provides us relative motion between two joints by computing the joint relative angles (JRA) over a complete gait cycle. JRA between two joints p1 and p2 can be defined as the angle formed by p1 and p2 with respect to a reference point r. Given the coordinates of 3 points p1, p2, and r in a 3-D space the angle p1, p2 formed by p1 --$>$ r --$>$ p2 can be calculated as

       \(\theta_{p_1,p_2} \)= \(\cos^{-1} \frac{ {p_{1}r.rp_{2}}}{\|{ p_{1}r }\|.\|{rp_{2}} \|}\)\\

\noindent The SPINE\_ BASE joint was selected as the reference point, since it remains almost stationary during walking. For the 25 skeletal joints, there is a total of 300 possible joint-pair combinations, which is a high-dimensional feature space. In our study we left out JRA involving 5 joints:  Hand Left/Right, Tip Left/Right and SpineBase. The position of the 4 former joints are usually irrelevant to gait and the latter if included would have given us just 2 joints(a line) instead of 3,which is required for an angle. So we are left with 20 joints, which gives us a total of 190 possible combinations.

\noindent In addition, out of these 190 not all joint-pair is relevant in gait feature representation. For example, JRAs between the SpineShoulder and the SpineMid joints does not represent any information related to human gait, since both these joints remain almost stationary when a person walks. Therefore, identifying the skeletal joint pairs that are relevant to human gait motion is imperative. The following figure gives an example of a JRA. 
\begin{figure}[h]
\centering
\includegraphics[scale=0.25]{angle.png}
\caption{JRA between Shoulder Left and Elbow Left}
\end{figure}

\newpage
\section{Design of the App } \label{ Design of the App} 
\noindent We designed a windows application on Visual Studio using the Kinect SDK for the purpose of extracting skeletal data and gait features which were discussed in the preceding sections. We named our App “TRACE”.

\noindent Here is the front page of TRACE. It has only one circular button. When pressed leads to the next page where the actual extraction happens.

\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{trace.png}
\caption{Trace}
\end{figure} 

\begin{figure}[h]
\centering
\includegraphics[scale=0.8]{john.png}
\caption{Skeletal View}
\end{figure}
\newpage
\noindent This Page has two buttons on the right for capturing the static and kinematic/dynamic data respectively. Data displayed on the top right is basically for the operator to know that the process is working fine. The number in blue indicates the joints currently being tracked by the Kinect. 

\noindent The next 3 are distance measurement between various joints. The final 3 are used for displaying angles, currently null since only the static button has been pressed.

\noindent The two figures below show how TRACE writes the static and dynamic data in CSV format. Each new line represents each frame of the walking sequence captured.\\
\begin{figure}[h]
\centering
\includegraphics[scale=0.6]{static.png}
\caption{Static data in CSV format}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[scale=0.6]{dynamic.png}
\caption{Dynamic data in CSV format}
\end{figure}


\section{Gait Database} \label{Gait Database}

\noindent Since a standard gait dataset acquired with the Kinect sensor is not available, we have collected a set of gait samples. The gait database consisted of 8 participants (5 males and 3 females) who were asked to walk naturally in front of the Kinect, each participant was asked to walk 10 times giving us a total of 80 gait samples. Out of this, 8 gait samples of each participant were used in the training set giving us a total of 64 samples for training. Remaining 2 gait samples was used for testing, giving us 16 testing samples.

\noindent Apart from that, we also collected a single gait sample from 12 other different participants. These samples were then added to training set to degrade it. This was done to prevent the classifiers from overgeneralizing the data and checking their performance in the presence of outliners. Hence the final training set consisted of 76 gait samples.

\newpage
\section{Overhead Processing} \label{Overhead Processing} 
\noindent All the static feature data that was obtained for the 3 second interval was averaged out by calculating the mean for each feature.                                                                                                                                                                                                               Since we are interested in tracking the changes of the kinematic data, the same procedure cannot be used. Also Kinect having limited precision and frame rate is prone to noisy acquisitions, to smoothen this out we pass all the kinematic data through a moving average filter. Through trial and error we found $1/4$ to be the best mask for this data.
The figure below demonstrates the smoothening effect of the moving average filter. Notice the smooth peaks and troughs in the filtered output.

\begin{figure}[h]
\centering
\includegraphics[scale=0.7]{filter.png}
\caption{Effect of the Moving Average Filter (pink represents the original data, blue displays the filtered output)}
\end{figure}
\newpage
\section{Gait Cycle Detection} \label{Gait Cycle Detection} 

\noindent Regular human walking is considered to be a cyclic motion, which repeats in a relatively stable frequency. Hence our first task is to extract one complete gait cycle, as it represents the complete gait signature. The figure below is a nice pictorial representation of a gait cycle.\\


\begin{figure}[h]
\centering
\includegraphics[scale=0.3]{gaitoriginal.jpg}
\caption{Phases Of the Gait cycle}
\end{figure}
 
\noindent In order to identify gait cycles, the distance between the Ankle Left and Ankle Right joints was tracked over time. A moving average filter was used to smoothen this distance. During walking, the distance between the two ankle joints will be at maximum when the right and the left leg are farthest apart and will be at minimum when the legs are in the rest (standing) position. Therefore, by detecting three subsequent minima, it is possible to find the occurrences of the two legs in the rest position, which corresponds to the beginning, middle, and ending points of a complete gait cycle, respectively.                                         

\newpage
\noindent The following figure explains this concept.

\begin{figure}[h]
\centering
\includegraphics[scale=0.85]{bd.png}
\caption{Process flow behind the gait cycle detection}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[scale=0.15]{oneGaitCycle.png}
\caption{Detection of a complete gait cycle by tracking the distance between the left and right ankle joints (red line connects the 3 subsequent minima)}
\end{figure}

\noindent The JRA data for this one gait cycle was extracted and considered. The rest of the kinematic features were averaged out for this period and the variances were calculated on the means of this cycle.\\
\newpage
